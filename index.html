<!DOCTYPE html>
<html lang="zh-TW">

<head>
	<meta charset="UTF-8">
	<link rel="stylesheet" href="main.css">
	<!-- <script src="main.js"></script> -->
	<title>MIRlab - Chih-Hsiang, Hsu RD Page</title>
</head>

<body>
	<div id="title">
		<h1 id="chih-hsiang-hsu">Chih-Hsiang, Hsu (許智翔)</h1>
		<hr>
	</div>
	<div id="toc_container">
		<p class="toc_title">Contents</p>
		<ul class="toc_list">
			<li><a href="#research">1 Research</a>
				<ul>
					<li><a href="#intro">1.1 Introduction</a></li>
				</ul>
				<ul>
					<li><a href="#paper-survey">1.2 Paper survey</a></li>
				</ul>
			</li>
			<li><a href="#meeting-slides">2 Meeting slides</a></li>
			<li><a href="#contact">3 Contact</a></li>
		</ul>
	</div>
	
	<div id="block">
		<h1 id="research">Research</h1>
		<hr>
		
		<h2 id="intro">Introduction</h2>
		We aims to do sports analysis by reconstructing 3D human pose from video source. This task can be split into
		two steps:
		<ul>
		<li>2D keypoints estimation: estimating the 2D keypoints on human body. The model we use is <a href="https://arxiv.org/abs/2104.02300">DEKR</a>.
		</li>
		<li>2D-to-3D lifting: reconstruct 3D human pose from a sequence of 2D keypoints. The model we use is
			<a href="https://arxiv.org/abs/2103.10455">Poseformer</a></li>
		</li>
		</ul>
		2D-to-3D lifting is actually an ill-posed problem. Many 3D poses can have the same 2D projection onto camera plane.
		For example, a person streching her arm forward has exactly the same 2D projection with her arm streching backward.
		We find that even the SOTA model has difficulty predicting the correct direction. This mostly happens on limbs.
		Hence we are finding a solution using pose hypotheses.<br>
		Given a seqeunce of predicted 3D human poses, there should be some erroneous pose with wrong depth. For each pose, 
		We generate several hypotheses of the same 2D projection and the answer should lie in these hypotheses. Then we use 
		dynamic programming considering the continuity of consequent poses to find a sequence of 3D human poses such that 
		it is closer to the answer.
		
		<h2 id="paper-survey">Paper survey</h2>
		<ul>
		<li>2d keypoints estimation
			<ul>
			<li>CVPR 2019 - Deep High-Resolution Representation Learning for Human Pose Estimation
				<ul>
				<li>Paper: <a href="https://arxiv.org/abs/1902.09212">https://arxiv.org/abs/1902.09212</a></li>
				<li>Code: <a href="GitHub">https://github.com/leoxiaobin/deep-high-resolution-net.pytorch</a></li>
				</ul>
			</li>
			<li>CVPR 2021 - Bottom-Up Human Pose Estimation Via Disentangled Keypoint Regression
				<ul>
				<li>Paper: <a href="https://arxiv.org/abs/2104.02300">https://arxiv.org/abs/2104.02300</a></li>
				<li>Code: <a href="GitHub">https://github.com/HRNet/DEKR</a></li>
				<li>Notes: best solution for 2d human pose estimation</li>
				</ul>
			</li>
			</ul>
		</li>

		<li>Multi-hypotheses pose estimation
			<ul>
			<li>ICCV 2017 - Generating Multiple Diverse Hypotheses for Human 3D Pose Consistent with 2D Joint Detections
				<ul>
				<li>Paper: <a href="https://arxiv.org/abs/1702.02258">https://arxiv.org/abs/1702.02258</a></li>
				</ul>
			</li>
			<li>CVPR 2019 - Generating Multiple Hypotheses for 3D Human Pose Estimation with Mixture Density Network
				<ul>
				<li>Paper: <a href="https://arxiv.org/abs/1904.05547">https://arxiv.org/abs/1904.05547</a></li>
				<li>Code: <a href="GitHub">https://github.com/chaneyddtt/Generating-Multiple-Hypotheses-for-3D-Human-Pose-Estimation-with-Mixture-Density-Network</a></li>
				</ul>
			</li>
			<li>ICCV 2021 - Probabilistic Monocular 3D Human Pose Estimation with Normalizing Flows
				<ul>
				<li>Paper: <a href="https://arxiv.org/abs/2107.13788">https://arxiv.org/abs/2107.13788</a></li>
				<li>Code: <a href="GitHub">https://github.com/twehrbein/Probabilistic-Monocular-3D-Human-Pose-Estimation-with-Normalizing-Flows</a></li>
				</ul>
			</li>
			<li>CVPR 2022 - MHFormer: Multi-Hypothesis Transformer for 3D Human Pose Estimation
				<ul>
				<li>Paper: <a href="https://arxiv.org/abs/2111.12707">https://arxiv.org/abs/2111.12707</a></li>
				<li>Code: <a href="GitHub">https://github.com/Vegetebird/MHFormer</a></li>
				<li>Notes: there are several unsolved problems in this paper, which are mentioned at <a href="https://docs.google.com/presentation/d/1aXCfWwJpe3dKVOuIOHzL0LESQ9TrLYLG28u0oe9dU34/edit?usp=sharing">meeting slide 2022/11/02</a></li>
				</ul>
			</li>
			</ul>
		</li>

		<li>Geometry constraints on human pose estimation
			<ul>
			<li>CVPR 2019 - Self-Supervised Learning of 3D Human Pose using Multi-view Geometry
				<ul>
				<li>Paper: <a href="https://arxiv.org/abs/1903.02330">https://arxiv.org/abs/1903.02330</a></li>
				<li>Code: <a href="GitHub">https://github.com/mkocabas/EpipolarPose</a></li>
				<li>Notes: MPJPE (L2-norm loss) is said to be not sufficient</li>
				</ul>
			</li>
			<li>IEEE 2021 - Anatomy-aware 3D Human Pose Estimation with Bone-based Pose Decomposition
				<ul>
				<li>Paper: <a href="https://arxiv.org/abs/2002.10322">https://arxiv.org/abs/2002.10322</a></li>
				<li>Code: <a href="GitHub">https://github.com/sunnychencool/Anatomy3D</a></li>
				</ul>
			</li>
			</ul>
		</li>

		<li>Human pose estimation
			<ul>
			<li>CVPR 2019 - 3D human pose estimation in video with temporal convolutions and semi-supervised training
				<ul>
				<li>Paper: <a href="https://arxiv.org/abs/1811.11742">https://arxiv.org/abs/1811.11742</a></li>
				<li>Code: <a href="GitHub">https://github.com/facebookresearch/VideoPose3D</a></li>
				</ul>
			</li>
			<li>CVPR 2019 - Semantic Graph Convolutional Networks for 3D Human Pose Regression
				<ul>
				<li>Paper: <a href="https://arxiv.org/abs/1904.03345">https://arxiv.org/abs/1904.03345</a></li>
				<li>Code: <a href="GitHub">https://github.com/garyzhao/SemGCN</a></li>
				</ul>
			</li>
			<li>2020 - A Graph Attention Spatio-temporal Convolutional Network for 3D Human Pose Estimation in Video
				<ul>
				<li>Paper: <a href="https://arxiv.org/abs/2003.14179">https://arxiv.org/abs/2003.14179</a></li>
				<li>Code: <a href="GitHub">https://github.com/fabro66/GAST-Net-3DPoseEstimation</a></li>
				</ul>
			</li>
			<li>ICCV 2021 - 3D Human Pose Estimation with Spatial and Temporal Transformers
				<ul>
				<li>Paper: <a href="https://arxiv.org/abs/2103.10455">https://arxiv.org/abs/2103.10455</a></li>
				<li>Code: <a href="GitHub">https://github.com/zczcwh/PoseFormer</a></li>
				</ul>
			</li>
			<li>IEEE 2022 - Limb Pose Aware Networks for Monocular 3D Pose Estimation
				<ul>
				<li>Paper: <a href="https://ieeexplore.ieee.org/document/9663053">https://ieeexplore.ieee.org/document/9663053</a></li>
				<li>Notes: Using additional information from raw images</li>
				</ul>
			</li>
			</ul>
		</li>

		<li>Transformer on computer vision
			<ul>
			<li>ICLR 2021 An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale
				<ul>
				<li>Paper: <a href="https://arxiv.org/abs/2010.11929">https://arxiv.org/abs/2010.11929</a></li>
				<li>Code: <a href="GitHub">https://github.com/google-research/vision_transformer</a></li>
				</ul>
			</li>
			</ul>
		</li>

		<li>Object pose estimation in 6-dof
			<ul>
			<li>CVPR 2022 - EPro-PnP: Generalized End-to-End Probabilistic Perspective-n-Points for Monocular Object Pose Estimation
				<ul>
				<li>Paper: <a href="https://arxiv.org/abs/2203.13254">https://arxiv.org/abs/2203.13254</a></li>
				<li>Code: <a href="GitHub">https://github.com/tjiiv-cprg/EPro-PnP</a></li>
				</ul>
			</li>
			</ul>
		</li>

		</ul>
	</div>
			<!-- <li> -->
				<!-- <ul> -->
				<!-- <li>Paper: <a href=""></a></li> -->
				<!-- <li>Code: <a href=""></a></li> -->
				<!-- </ul> -->
			<!-- </li> -->
	
	<br/>
	
	<div id="block">
		<h1 id="meeting-slides">Meeting slides</h1>
		<hr>
		<ul>
			<li><a href="https://nas.mirlab.org/drive/d/s/sIRIwjlRnytY6ZYDaXx2693aA2xJLIYN/Sy7WV-aNePAMw0FKVVtvZDbmM3CwLJu0-7Ldg8LZnTgo">Introduction</a> - Introduction of our research.</li>
		</ul>
		<ul>
			<li><a href="https://docs.google.com/presentation/d/1aXCfWwJpe3dKVOuIOHzL0LESQ9TrLYLG28u0oe9dU34/edit?usp=sharing">2022/11/02</a> - Introducing recent models on multi-hypotheses 3d pose estimating. Discussing over possible improvement.</li>
		</ul>
		<ul>
			<li><a href="https://nas.mirlab.org/drive/d/s/rv8tBSq5beeDah0qo9wgkdMNY1qlFrbE/ny7TMAnPksAJ0uwVbuqeBOO7-g97BtNy-e7gglihoTgo">2023/01/11</a> - Estimating state probability with neural network.</li>
		</ul>
		<ul>
			<li><a href="https://nas.mirlab.org/drive/d/s/sOBn51kkZTxt1sKahNmC7PAaquWvjCfE/_SPcEm10pI19OUtJuo1cHG2YwztqVr6I-8LiAla5oTgo">2023/02/15</a> - Introducing dynamic programming with GMM-based probability estimation.</li>
		</ul>
		<ul>
			<li><a href="https://nas.mirlab.org/drive/d/s/srFtw3AW1gknqaAyusmIHor9AaeKHGpb/7fserjpTfm890R65NL3gbqFW8wKabQxt-grngXvxoTgo">2023/03/22</a> - Introducing tri-skeleton in the dynamic programming.</li>
		</ul>
	</div>
	
	<br/>

	<div id="block">
		<h1 id="contact">Contact</h1>
		<hr>
		<ul>
			<li>Email: andy.hsu@nas.mirlab.org</li>
			<li>Lab: <a href="http://mirlab.org/">Multimedia Information Retrieval Lab</a></li>
		</ul>
	</div>
</body>

</html>
